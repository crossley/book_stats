---
title: "Tutorial 9"
author: "Author: Matthew J. Crossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    toc_depth: 3
    fig_caption: yes
    # code_folding: show
    number_sections: false
    theme: cosmo
fontsize: 14pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, collapse=T)
```

```{r, echo=F}
library(data.table)
library(ggplot2)
library(ggpubr)
library(latex2exp)
```

## Work through these practice exercises
* It's a good idea to work through these on your own, but if
you get very stuck, solutions can be found
[here](tutorial_9_solutions.html)

### 1.
Suppose that researchers for a popular social media platform
are interested maximising the amount of time that users
spend on their app, and that they are faced with a tough
decision about whether or not the app should use a
continuous scroll feature. Since opinions on the research
team are split on the issue, they decide to perform an
experiment to clear things up. They implement the continuous
scroll feature and push it to their users. The average time
that a user spends on app currently is 58 minutes per day.
Thus they are interested in whether or not continuous scroll
increases this number. Suppose they obtain the following
sample from this experiment:

$$
x = \{ 63.97, 60.29, 85.60, 72.57, 54.65, 53.74, 69.13, 70.07, 67.19, 53.95 \}
$$

Test the hypothesis that infinite scroll had any effect
whatsoever (increased or decreased) time on app beyond 58
minutes per day assuming that the population variance of $X$
is $\sigma_X^2 = 10$. **Do not use `t.test`, `binim.test` or
any other built in full test function unless explicitly
instructed to do so.**

* Store the value of your observed test statistic in a
variable named `ans_1_test_stat_obs`.

* Store the lower critical value of your test in a variable
named `ans_1_critical_value_lower`.

* Store the upper critical value of your test in a variable
named `ans_1_critical_value_upper`.

* Store the lower bound of a 95% CI for your test statistic
in a variable named `ans_1_CI_lower`.

* Store the upper bound of a 95% CI for your test statistic
in a variable named `ans_1_CI_upper`.

* Store the p-value of your test in a variable named
`ans_1_p_value`.


### 2.
Suppose that a cognitive neuroscientist would like to
discover if the response a participant makes in a
2-alternative forced choice task can be predicted on the
basis of neural activity occurring 1 second before the motor
response is made. They train a machine learning classifier
to do this, and discover that it correctly predicts
participant choices in 63 out of 100 trials. Test the
hypothesis that their machine learning classifier predicts
participant choice at levels significantly different from
chance (i.e., above chance or below chance). **Do not use
`t.test`, `binim.test` or any other built in full test
function unless explicitly instructed to do so.**

* Store the value of your observed test statistic in a
variable named `ans_2_test_stat_obs`.

* Store the lower critical value of your test in a variable
named `ans_2_critical_value_lower`.

* Store the upper critical value of your test in a variable
named `ans_2_critical_value_upper`.

* Store the lower bound of a 95% CI for your test statistic
in a variable named `ans_2_CI_lower`.

* Store the upper bound of a 95% CI for your test statistic
in a variable named `ans_2_CI_upper`.

* Store the p-value of your test in a variable named
`ans_2_p_value`.

### 3.
Test the hypothesis that $\theta$ is different than 0.5,
where $\theta$ is a parameter of some random variable.  The
sampling distribution for $\hat{\theta}$ is shown in the
following figure and the observed test statistic
$\hat{\theta}_{obs}$ is shown in blue. Ensure that the type
I error rate of your test is $\alpha=0.05$.

```{r, echo=F, include=T}
xobs <- 0.75
a <- 0
b <- 1
x <- seq(a, b, 0.01)
fx <- dunif(x, a, b)
d <- data.table(x, fx)
ggplot(d, aes(x, fx)) +
  geom_line() +
  geom_segment(aes(x=a, xend=a, y=0, yend=fx[1])) +
  geom_segment(aes(x=b, xend=b, y=0, yend=fx[length(fx)])) +
  geom_segment(aes(x=xobs, xend=xobs, y=0, yend=fx[x==xobs]), colour='blue') +
  xlab(TeX("$\\theta_x$")) +
  ylab(TeX("$P(\\hat{\\theta} = \\theta_x)$"))
```


* Store the lower critical value of your test in a variable
named `ans_3_critical_value_lower`.

* Store the upper critical value of your test in a variable
named `ans_3_critical_value_upper`.

* Store the lower bound of a 95% CI for $\hat{\theta}$ in a
variable named `ans_3_CI_lower`.

* Store the upper bound of a 95% CI for $\hat{\theta}$ in a
variable named `ans_3_CI_upper`.

* Store the p-value of this test in a variable named
`ans_3_p_value`.


### 4.
```{r, echo=F, fig.width=10}
n <- 2

mu_x_0 <- 5
sigma_x <-  2 / sqrt(n)
x_crit_lower <- qnorm(0.05, mu_x_0, sigma_x, lower.tail=T)
x_crit_upper <- qnorm(0.95, mu_x_0, sigma_x, lower.tail=T)
mu_x_1 <- mu_x_0 + 1

x <- seq(mu_x_0 - 5*sigma_x, mu_x_1 + 5*sigma_x, 0.01)
fx0 <- dnorm(x, mu_x_0, sigma_x)
fx1 <- dnorm(x, mu_x_1, sigma_x)
d <- data.table(x, fx0, fx1)
d[x > x_crit_lower & x < x_crit_upper, region0 := 'I'] # confidence
d[x > x_crit_lower & x < x_crit_upper, region1 := 'II'] # beta
d[x < x_crit_lower, region0 := 'III'] # alpha lower
d[x < x_crit_lower, region1 := 'IV'] # power lower
d[x > x_crit_upper, region0 := 'V'] # alpha upper
d[x > x_crit_upper, region1 := 'VI'] # power upper

a <- 0.5
ggplot(d, aes(x=x)) +
  geom_line(aes(y=fx0)) +
  geom_line(aes(y=fx1)) +
  geom_vline(xintercept=x_crit_lower, linetype=2) +
  geom_vline(xintercept=x_crit_upper, linetype=2) +
  geom_ribbon(data=d[x < x_crit_lower], aes(x=x, ymin=0, ymax=fx0, fill=region0), alpha=a) +
  geom_ribbon(data=d[x > x_crit_upper], aes(x=x, ymin=0, ymax=fx0, fill=region0), alpha=a) +
  geom_ribbon(data=d[x > x_crit_lower & x < x_crit_upper],
              aes(x=x, ymin=0, ymax=fx0, fill=region0), alpha=a) +
  geom_ribbon(data=d[x < x_crit_lower], aes(x=x, ymin=0, ymax=fx1, fill=region1), alpha=a) +
  geom_ribbon(data=d[x > x_crit_upper], aes(x=x, ymin=0, ymax=fx1, fill=region1), alpha=a) +
  geom_ribbon(data=d[x > x_crit_lower & x < x_crit_upper], 
              aes(x=x, ymin=0, ymax=fx1, fill=region1), alpha=a) +
  scale_x_continuous(breaks=c(mu_x_1, mu_x_0), labels=c('H1', 'H0')) +
  ylab('Probability Density') +
  theme(legend.title = element_blank()) +
  annotate('text', x=mu_x_0, y=0.25, label='I') +
  annotate('text', x=mu_x_1, y=0.25, label='II') +
  annotate('text', x=2.1, y=0.02, label='III') +
  annotate('text', x=2.3, y=0, label='IV') +
  annotate('text', x=7.7, y=0.02, label='V') +
  annotate('text', x=7.7, y=0.1, label='VI')
```

Please respond by assigning `"confidence"`, `"alpha"`,
`"beta"`, or `"power"` to the variables requested below.
Note that the dashed lines in the above figure are the
critical values. 

* What quantity does region I in the above plot contribute
to? Store your answer in a variable named `ans_4a`.

* What quantity does region II in the above plot contribute
to? Store your answer in a variable named `ans_4b`.

* What quantity does region III in the above plot contribute
to? Store your answer in a variable named `ans_4c`.

* What quantity does region IV in the above plot contribute
to? Store your answer in a variable named `ans_4d`.

* What quantity does region V in the above plot contribute
to? Store your answer in a variable named `ans_4e`.

* What quantity does region VI in the above plot contribute
to? Store your answer in a variable named `ans_4f`.


## Preamble

These exercises rely on magnetoencephalography (MEG) data
collected from a single participant while they performed a
category learning experiment. On each trial of the category
learning experiment, the participant viewed a circular sine
wave grating, and had to push a button to indicate whether
they believed the stimulus belonged to category A or
category B. We have seen and worked with this type of
category learning experiment many times throughout this
course, and it is further described by the following figure.

<center>
![FigName](img/cats.png){width=300px}
</center>

MEG is used to record the time-series of magnetic and
electric potentials at the scalp, which are generated by the
activity of neurons. There are many sensors, each configured
to pick up signal from a different position on the scalp.
This is shown in the following figure (the text labels
indicate the channel name and are placed approximately where
the MEG sensor is located on a real head).

<center>
![FigName](img/MEG_2.png){width=300px}
</center>

The data file that we will be working with is arranged into
*epochs* aligned to stimulus presentation. This means that
every time a stimulus is presented we say that an epoch has
occurred. We then assign a time of $t=0$ to the exact moment
the stimulus appeared. We then typically look at the neural
time series from just before the stimulus appeared to a
little while after the stimulus has appeared. For this data,
each epoch starts 0.1 seconds before stimulus onset, and
concludes 0.3 seconds after stimulus onset. The following
figure shows the MEG signal at every sensory location across
the entire scalp for 5 time points within this $[-0.1s,
0.3s]$ interval.

<center>
![FigName](img/MEG_1.png){width=550px}
</center>

* The data can be read into a `data.table` and the columns
renamed to eliinate spaces by using the following code:

```{r message=F}
library(stringr)
d <- fread('https://crossley.github.io/cogs2020/data/eeg/epochs.txt')

# The column names that come from this file have spaces
# This line removes those spaces (depends on the `stringr` package)
names(d) <- str_replace_all(names(d), c(" " = "." , "," = "" ))
```

- The `time` column contains times in seconds relative to
stimulus onset. Stimulus onset always occurs at $0$ seconds.

- The `condition` column indicates which category the
stimulus belonged to for the given `epoch`. We won't make
use of this column here, and we will remove it below.

- The `epoch` column is the epoch number. You can think of
this like we have usually thought of `trial` columns in
examples throughout the course.

- The many different `MEG xyz` columns contain the actual
neural time series signals for each sensor. See the above
figure for how these column names map onto scalp positions.

- The `time` column contains times in seconds relative to
stimulus onset. Stimulus onset always occurs at $0$ seconds.

- The `condition` column indicates which category the
stimulus belonged to for the given `epoch`. We won't make
use of this column here, and we will remove it below.

- The `epoch` column is the epoch number. You can think of
this like we have usually thought of `trial` columns in
examples throughout the course.

- The many different `MEG xyz` columns contain the actual
neural time series signals for each sensor. See the above
figure for how these column names map onto scalp positions.

#### 1
Consider two random variables $X \sim \mathcal{N}(\mu_X,
\sigma_X)$ and $Y \sim \mathcal{N}(\mu_Y, \sigma_Y)$. Let
$X$ generate data for MEG channel 133 and $Y$ generate data
for MEG channel 135. Test the hypothesis that the mean MEG
signal for $t > 0$ in these two channels are significantly
different. When computing the mean MEG signal, keep epochs
separate and average over everything else. You should be
left with one observation per epoch. Assume that $\sigma_X =
\sigma_Y$ and also assume that $X$ and $Y$ are independent.

* Store the observed $t$ value of this test in a variable
named `ans_1_t_test_stat_obs`.

* Store the lower critical value in a variable
named `ans_1_critical_value_lower`.

* Store the upper critical value in a variable
named`ans_1_critical_value_upper`.

* Store the observed $95\%$ CI lower value in a variable
named`ans_1_CI_lower`

* Store the observed $95\%$ CI upper value in a variable
named`ans_1_CI_upper`

* Store the observed $p$-value in a variable
named`ans_1_p_value`

#### 2
Consider two random variables $X \sim \mathcal{N}(\mu_X,
\sigma_X)$ and $Y \sim \mathcal{N}(\mu_Y, \sigma_Y)$. Let
$X$ generate data for MEG channel 039 during the first 30
epochs and $Y$ generate data for MEG channel 039 during the
remaining epochs. Test the hypothesis that the mean MEG
signal for $t > 0$ in these two signals are significantly
different. Assume $X$ and $Y$ are independent but do not
assume that $\sigma_X=\sigma_Y$.

* Store the observed $t$ value of this test in a variable
named `ans_2_t_test_stat_obs`.

* Store the lower critical value in a variable
named `ans_2_critical_value_lower`.

* Store the upper critical value in a variable
named`ans_2_critical_value_upper`.

* Store the observed $95\%$ CI lower value in a variable
named`ans_2_CI_lower`

* Store the observed $95\%$ CI upper value in a variable
named`ans_2_CI_upper`

* Store the observed $p$-value in a variable
named`ans_2_p_value`

#### 3
Do you think two different MEG channels on the same persons
head are likely to be independent? Explain your reasoning in
a brief comment (no more than a sentence or two).

#### 4
Consider two random variables $X \sim \mathcal{N}(\mu_X,
\sigma_X)$ and $Y \sim \mathcal{N}(\mu_Y, \sigma_Y)$. Let
$X$ generate data for MEG channel 039 and $Y$ generate data
for MEG channel 135. Test the hypothesis that the mean MEG
signal per epoch for $t > 0$ in these two channels are
significantly different. Do not assume $X$ and $Y$ are
independent.

* Store the observed $t$ value of this test in a variable
named `ans_4_t_test_stat_obs`.

* Store the lower critical value in a variable
named `ans_4_critical_value_lower`.

* Store the upper critical value in a variable
named`ans_4_critical_value_upper`.

* Store the observed $95\%$ CI lower value in a variable
named`ans_4_CI_lower`

* Store the observed $95\%$ CI upper value in a variable
named`ans_4_CI_upper`

* Store the observed $p$-value in a variable
named`ans_4_p_value`
